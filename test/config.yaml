id: 'dummy_ppo'
algo_params:
  k_epochs: 10
  batch_size: 128
  min_batch_size: 2048
  episodes: 10000
  lam: 0.95
  gamma: 0.99
  actor_lr: 3e-5
  critic_lr: 7e-5
  std_min_clip:  0.1
  eps_clip: 0.4
  beta: 0.1
  max_steps: 10000
  
network_params:
  hid_layers: [128, 64]
  nets: 'separate'
  act_fn: 'relu'
  action_space: 'cont'