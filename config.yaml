algo_params:
  name: 'dummy_ppo'
  k_epochs: 7
  batch_size: 64
  min_batch_size: 2048
  episodes: 10000
  lam: 0.95
  gamma: 0.99
  actor_lr: 0.00005
  critic_lr: 0.0001
  std_min_clip:  0.1
  eps_clip: 0.2
  beta: 0.07
  max_steps: 15000
  max_reward: 100
  
network_params:
  hid_layers: [512, 256]
  net_is_shared: false
  act_fn: 'relu'
  action_space: 'cont'
  init_logstd: 0.1

env_params:
  obs_scale_factor: 0.1
  positions: [[-2.5, -2.0]]
  angles: [0, 45, 90, 135, 180, 225, 270, 315]
  noise_std: 15
